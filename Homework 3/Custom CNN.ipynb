{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAML file with an absolute path\n",
    "with open('/home/tyler/yolov5/data/coco128.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# Extract the dataset path\n",
    "dataset_path = data['path']\n",
    "\n",
    "# Extract image paths and labels for train, val, and test sets\n",
    "train_image_paths = data.get('train', [])\n",
    "train_labels = data.get('train_labels', [])  # Adjust the key based on your YAML structure\n",
    "\n",
    "val_image_paths = data.get('val', [])\n",
    "val_labels = data.get('val_labels', [])  # Adjust the key based on your YAML structure\n",
    "\n",
    "test_image_paths = data.get('test', [])\n",
    "test_labels = data.get('test_labels', [])  # Adjust the key based on your YAML structure\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "target_size = (224, 224)\n",
    "\n",
    "def custom_data_generator(image_paths, labels, batch_size=batch_size, target_size=target_size):\n",
    "    while True:\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_paths = image_paths[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "\n",
    "            # Load and preprocess batch images\n",
    "            batch_images = load_and_preprocess_images(batch_paths, dataset_path, target_size)\n",
    "\n",
    "            # Assuming batch_labels are already in one-hot encoded format\n",
    "            batch_labels_encoded = np.array(batch_labels)\n",
    "\n",
    "            yield batch_images, batch_labels_encoded\n",
    "\n",
    "def load_and_preprocess_images(paths, dataset_path, target_size=(416, 416)):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        full_path = os.path.join(dataset_path, path)\n",
    "        print(\"Full Path:\", full_path)\n",
    "\n",
    "        try:\n",
    "            if os.path.isfile(full_path) and not os.path.basename(full_path).startswith('.'):\n",
    "                # Load image using PIL\n",
    "                img = Image.open(full_path)\n",
    "\n",
    "                # Convert image to numpy array\n",
    "                img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "                # Resize the image to the target size\n",
    "                img_array = cv2.resize(img_array, target_size)\n",
    "\n",
    "                images.append(img_array)\n",
    "\n",
    "                # Print the shape of the loaded image\n",
    "                print(\"Image Shape:\", img_array.shape)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {full_path}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the number of steps per epoch for training\n",
    "steps_per_epoch = max(1, len(train_image_paths) // batch_size)\n",
    "\n",
    "# Calculate the number of steps per epoch for validation\n",
    "validation_steps = max(1, len(val_image_paths) // batch_size)\n",
    "\n",
    "# Use the custom data generator\n",
    "custom_train_generator = custom_data_generator(train_image_paths, train_labels, target_size=target_size)\n",
    "custom_test_generator = custom_data_generator(test_image_paths, test_labels, target_size=target_size)\n",
    "\n",
    "# Use the custom data generator to create train and test generators\n",
    "train_generator = custom_data_generator(train_image_paths, train_labels, batch_size=batch_size, target_size=target_size)\n",
    "test_generator = custom_data_generator(test_image_paths, test_labels, batch_size=batch_size, target_size=target_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture (simple image classification)\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(units=80, activation='softmax')  # num_classes is the number of object classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile your model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Path: ../datasets/coco128/i\n",
      "Full Path: ../datasets/coco128/m\n",
      "Full Path: ../datasets/coco128/a\n",
      "Full Path: ../datasets/coco128/g\n",
      "Full Path: ../datasets/coco128/e\n",
      "Full Path: ../datasets/coco128/s\n",
      "Full Path: /\n",
      "Full Path: ../datasets/coco128/t\n",
      "Full Path: ../datasets/coco128/r\n",
      "Full Path: ../datasets/coco128/a\n",
      "Full Path: ../datasets/coco128/i\n",
      "Full Path: ../datasets/coco128/n\n",
      "Full Path: ../datasets/coco128/2\n",
      "Full Path: ../datasets/coco128/0\n",
      "Full Path: ../datasets/coco128/1\n",
      "Full Path: ../datasets/coco128/7\n",
      "Batch Shape: (0,)\n",
      "Full Path: ../datasets/coco128/i\n",
      "Full Path: ../datasets/coco128/m\n",
      "Full Path: ../datasets/coco128/a\n",
      "Full Path: ../datasets/coco128/g\n",
      "Full Path: ../datasets/coco128/e\n",
      "Full Path: ../datasets/coco128/s\n",
      "Full Path: /\n",
      "Full Path: ../datasets/coco128/t\n",
      "Full Path: ../datasets/coco128/r\n",
      "Full Path: ../datasets/coco128/a\n",
      "Full Path: ../datasets/coco128/i\n",
      "Full Path: ../datasets/coco128/n\n",
      "Full Path: ../datasets/coco128/2\n",
      "Full Path: ../datasets/coco128/0\n",
      "Full Path: ../datasets/coco128/1\n",
      "Full Path: ../datasets/coco128/7\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_24' (type Sequential).\n    \n    Input 0 of layer \"conv2d_72\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_24' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/tyler/Automail Mobile Pocket/Grad School Information/Deep Learning/Homework/Homework 3/Custom CNN.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Print only the first batch for inspection\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Fit the model using the generators\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(custom_train_generator, epochs\u001b[39m=\u001b[39;49mepochs, steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49mcustom_test_generator, validation_steps\u001b[39m=\u001b[39;49mvalidation_steps)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filethh8qa27.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/tyler/.local/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_24' (type Sequential).\n    \n    Input 0 of layer \"conv2d_72\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_24' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "for batch_images, batch_labels_encoded in custom_train_generator:\n",
    "    print(\"Batch Shape:\", batch_images.shape)\n",
    "    break  # Print only the first batch for inspection\n",
    "\n",
    "# Fit the model using the generators\n",
    "model.fit(custom_train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "          validation_data=custom_test_generator, validation_steps=validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/tyler/Automail Mobile Pocket/Grad School Information/Deep Learning/Homework/Homework 3/Custom CNN.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Evaluate your model on the test set\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_generator \u001b[39m=\u001b[39m custom_data_generator(test_image_paths, test_labels, batch_size, target_size)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(test_image_paths) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tyler/Automail%20Mobile%20Pocket/Grad%20School%20Information/Deep%20Learning/Homework/Homework%203/Custom%20CNN.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_loss, test_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_generator, steps\u001b[39m=\u001b[39mtest_steps)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Evaluate your model on the test set\n",
    "test_generator = custom_data_generator(test_image_paths, test_labels, batch_size, target_size)\n",
    "test_steps = len(test_image_paths) // batch_size\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "model.save('custom_object_detection_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
